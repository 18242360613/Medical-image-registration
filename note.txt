*_ver1: data trained with 280 samples and test on 100 samples from combinations of the first 20 subjects. 16 epochs with 4 per minibatch, list are shuffled for every new epoch. Optimizer is by Adam.

*_ver2: data trained with combinations from within the first 30 subjects. Combinations from within the rest 10 subjects are used as test.
        (Should verify a second test set built from combinations between the first 30 and the rest 10)
        No regularization strength is applied. Simpler architecture with 32-64-64-64-32. 32 epochs with 6 per minibatch, list are shuffled for every epoch. Optimizer is by SGD.

*_ver3: Same data as ver1. Optimizer = SGD(decay = 1e-6, nestrov = True). No regularization. Simpler architecture. 20 epochs. 

*_ver4: Same data as _ver2. Optimizer = SGD(decay = 1e-6, nestrov = True). No regularization. Branched Architecture (last block branched), 40 epochs.

*_ver5: Adam(1e-3), No regularization. Branched Architecture (last block branched), 20 epochs. Batch_size  = 10

*_ver5_45: Only trained with the first 45 samples

*_ver6: Only 10 epochs.

*_ver6_r1e-5: regularization strength = 1e-5

*_ver6_5: only 5 epochs.

*_ver6_a1e-4: learning rate = 1e-4, 10 epochs.

*_ver7: 10 epochs, learning rate = 1e-4, regularizatoin strength = 1e-6
